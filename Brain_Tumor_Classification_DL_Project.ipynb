{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2f9da7fe",
      "metadata": {
        "id": "2f9da7fe"
      },
      "source": [
        "# **Project Name**    - Brain Tumor Classification Using Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8244f052",
      "metadata": {
        "id": "8244f052"
      },
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Hari Khamala S\n"
      ]
    },
   
    {
      "cell_type": "markdown",
      "id": "d0340320",
      "metadata": {
        "id": "d0340320"
      },
      "source": [
        "### üîç **Problem Statement**\n",
        "This project aims to develop a deep learning-based solution for classifying brain MRI images into multiple categories according to tumor type. It involves building a custom CNN model from scratch and enhancing performance through transfer learning using pretrained models. The project also includes deploying a user-friendly Streamlit web application to enable real-time tumor type predictions from uploaded MRI images."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7f37002",
      "metadata": {
        "id": "d7f37002"
      },
      "source": [
        "### üí° **Real-Time Business Use Cases**\n",
        "- **AI-Assisted Medical Diagnosis**: Provide radiologists with AI-powered tools to quickly classify brain tumors based on MRI images.\n",
        "- **Early Detection and Patient Triage**: Automatically flag high-risk MRI images for immediate specialist review.\n",
        "- **Research and Clinical Trials**: Use AI tools to segment patient datasets by tumor type.\n",
        "- **Second-Opinion AI Systems**: Deploy classification tools in remote or under-resourced healthcare regions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f5a76e3",
      "metadata": {
        "id": "9f5a76e3"
      },
      "source": [
        "### üîÅ **Project Workflow**\n",
        "1. **Understand the Dataset**\n",
        "2. **Data Preprocessing**\n",
        "3. **Data Augmentation**\n",
        "4. **Model Building (Custom CNN & Transfer Learning)**\n",
        "5. **Model Training**\n",
        "6. **Model Evaluation**\n",
        "7. **Model Comparison**\n",
        "8. **Streamlit Application Deployment**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e8ba46c",
      "metadata": {
        "id": "9e8ba46c"
      },
      "source": [
        "### üìÅ **Dataset**\n",
        "**Source**: [Brain Tumor MRI Multi-Class Dataset](https://drive.google.com/drive/folders/1C9ww4JnZ2sh22I-hbt45OR16o4ljGxju)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc9c60ea",
      "metadata": {
        "id": "bc9c60ea"
      },
      "outputs": [],
      "source": [
        "# üì• Load and Explore the Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_dir = 'path_to_downloaded_dataset'\n",
        "categories = os.listdir(data_dir)\n",
        "print(\"Tumor Categories:\", categories)\n",
        "\n",
        "# Count images per class\n",
        "for category in categories:\n",
        "    print(category, \":\", len(os.listdir(os.path.join(data_dir, category))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìñ What This Code Does: Load and Explore the Dataset\n",
        "\n",
        "This cell performs the initial exploration of the brain tumor dataset. Here's a breakdown of what it does:\n",
        "\n",
        "- **Imports essential libraries** for data processing, visualization, and image handling.\n",
        "- **Specifies the dataset directory** using the `data_dir` variable. This should point to the folder that contains subfolders for each tumor category.\n",
        "- **Lists the tumor categories** (e.g., glioma_tumor, meningioma_tumor, etc.) by reading subfolder names under the dataset directory.\n",
        "- **Counts the number of images** in each tumor class to help check for class balance or imbalance in the dataset.\n",
        "\n",
        "üìå This step is important to:\n",
        "- Verify dataset structure.\n",
        "- Understand category-wise distribution.\n",
        "- Confirm data availability before preprocessing and modeling.\n",
        "\n",
        "üß† Expected Output Example:\n",
        "\n",
        "Tumor Categories: ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
        "\n",
        "glioma_tumor : 800\n",
        "\n",
        "meningioma_tumor : 500\n",
        "\n",
        "no_tumor : 300\n",
        "\n",
        "pituitary_tumor : 600\n",
        "\n",
        "\n",
        "Note: Since we are not executing this code (due to dataset size), this explanation ensures viewers and readers understand the purpose clearly.\n"
      ],
      "metadata": {
        "id": "lDzGHe5sGo2Y"
      },
      "id": "lDzGHe5sGo2Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc16507",
      "metadata": {
        "id": "2cc16507"
      },
      "outputs": [],
      "source": [
        "# üîÑ Data Preprocessing and Augmentation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Preprocessing and Augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   validation_split=0.2,\n",
        "                                   rotation_range=15,\n",
        "                                   zoom_range=0.1,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üßº What This Code Does: Data Preprocessing and Augmentation\n",
        "\n",
        "This block performs data preprocessing and augmentation to prepare the brain MRI images for training and validation. Here's what each part does:\n",
        "\n",
        "- **`ImageDataGenerator`** is used to:\n",
        "  - **Normalize images** (scale pixel values from [0‚Äì255] to [0‚Äì1]).\n",
        "  - Apply **data augmentation** techniques like:\n",
        "    - Rotation (¬±15¬∞)\n",
        "    - Zooming (up to 10%)\n",
        "    - Horizontal flipping\n",
        "\n",
        "- The dataset is **split into training and validation sets** using `validation_split=0.2`.\n",
        "\n",
        "- **`flow_from_directory()`** loads the image files directly from the directory and:\n",
        "  - Resizes them to 224√ó224 (compatible with many CNN architectures).\n",
        "  - Generates batches of augmented image-label pairs.\n",
        "  - Uses **categorical labels** since this is a multi-class classification problem.\n",
        "\n",
        "üìå This step ensures:\n",
        "- Improved model generalization.\n",
        "- Balanced training-validation split from the same directory.\n",
        "\n",
        "üß† Expected Output Example:\n",
        "\n",
        "Found 1760 images belonging to 4 classes.\n",
        "\n",
        "Found 440 images belonging to 4 classes.\n",
        "\n",
        "Note: The actual numbers depend on your dataset size and the `validation_split` used.\n"
      ],
      "metadata": {
        "id": "mCFZfeU8HgCO"
      },
      "id": "mCFZfeU8HgCO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ff0ab0a",
      "metadata": {
        "id": "3ff0ab0a"
      },
      "outputs": [],
      "source": [
        "# üß† Build Custom CNN Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "model_cnn = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(len(categories), activation='softmax')\n",
        "])\n",
        "\n",
        "model_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† What This Code Does: Build Custom CNN Model\n",
        "\n",
        "This block defines a **custom Convolutional Neural Network (CNN)** architecture for classifying MRI brain images into 4 tumor categories.\n",
        "\n",
        "#### üîß Architecture Overview:\n",
        "- **Conv2D + MaxPooling + BatchNormalization (x2)**: Feature extraction layers to detect tumor patterns.\n",
        "- **Flatten**: Converts 2D feature maps into a 1D vector for the dense layer.\n",
        "- **Dense(128)**: Fully connected layer to learn complex patterns.\n",
        "- **Dropout(0.3)**: Regularization to prevent overfitting.\n",
        "- **Dense(output)**: Final softmax layer for 4-class classification.\n",
        "\n",
        "#### ‚öôÔ∏è Compilation:\n",
        "- **Optimizer**: `adam` ‚Äî adaptive learning rate.\n",
        "- **Loss**: `categorical_crossentropy` ‚Äî used for multi-class classification.\n",
        "- **Metrics**: `accuracy` ‚Äî to track training performance.\n",
        "\n",
        "üìå This step builds the base deep learning model using only raw image features ‚Äî no transfer learning is used here.\n",
        "\n",
        "üß† Expected Output (summary portion):\n",
        "\n",
        "Model: \"sequential\"\n",
        "\n",
        "Layer (type) Output Shape Param #\n",
        "\n",
        "conv2d (Conv2D) (None, 222, 222, 32) 896\n",
        "\n",
        "max_pooling2d (MaxPooling2D) (None, 111, 111, 32) 0\n",
        "\n",
        "batch_normalization (BatchNormalization) (None, 111, 111, 32) ...\n",
        "\n",
        "...\n",
        "\n",
        "dense (Dense) (None, 128) 802944\n",
        "\n",
        "dropout (Dropout) (None, 128) 0\n",
        "\n",
        "dense_1 (Dense) (None, 4) 516\n",
        "\n",
        "Total params: ~1 million\n",
        "\n",
        "Trainable params: ~1 million\n",
        "\n",
        "\n",
        "üß™ This model will now be trained on the preprocessed dataset to learn tumor classification from scratch.\n"
      ],
      "metadata": {
        "id": "uScx00IlH6pq"
      },
      "id": "uScx00IlH6pq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9b9471",
      "metadata": {
        "id": "3a9b9471"
      },
      "outputs": [],
      "source": [
        "# üß† Transfer Learning with MobileNetV2\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(len(categories), activation='softmax')(x)\n",
        "\n",
        "model_transfer = Model(inputs=base_model.input, outputs=predictions)\n",
        "model_transfer.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_transfer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîÅ What This Code Does: Transfer Learning with MobileNetV2\n",
        "\n",
        "This block implements **transfer learning** using the pre-trained **MobileNetV2** model to classify brain tumor images. Transfer learning allows leveraging learned features from large-scale datasets (like ImageNet) to improve performance and reduce training time on smaller medical datasets.\n",
        "\n",
        "#### üîß Steps Explained:\n",
        "- **Load MobileNetV2** with:\n",
        "  - `include_top=False` ‚Üí removes default classifier layer\n",
        "  - `weights='imagenet'` ‚Üí uses pretrained weights from ImageNet\n",
        "  - `input_shape=(224, 224, 3)` ‚Üí same as our image size\n",
        "- **Freeze `base_model`** ‚Üí we do not train its weights initially (`base_model.trainable = False`).\n",
        "\n",
        "#### üß† Added Classification Layers:\n",
        "- `GlobalAveragePooling2D()` ‚Äî reduces features globally instead of flattening.\n",
        "- `Dense(128, activation='relu')` ‚Äî learn task-specific features.\n",
        "- `Dense(4, activation='softmax')` ‚Äî final classification into 4 tumor types.\n",
        "\n",
        "#### ‚öôÔ∏è Compilation:\n",
        "- Same as custom CNN: `adam` optimizer, `categorical_crossentropy` loss, and accuracy metric.\n",
        "\n",
        "üìå Transfer learning is especially helpful here because:\n",
        "- Medical image datasets are small and expensive to annotate.\n",
        "- Pretrained models generalize better on limited data.\n",
        "\n",
        "üß† Expected Output (summary portion):\n",
        "\n",
        "Model: \"model\"\n",
        "\n",
        "Layer (type) Output Shape Param #\n",
        "\n",
        "mobilenetv2_1.00_224 (Functional) (None, 7, 7, 1280) 2257984\n",
        "\n",
        "global_average_pooling2d (GlobalAveragePooling2D) (None, 1280) ...\n",
        "\n",
        "dense (Dense) (None, 128) ...\n",
        "\n",
        "dense_1 (Dense) (None, 4) ...\n",
        "\n",
        "Total params: ~2.3 million\n",
        "\n",
        "Trainable params: only classification head (~130K)\n",
        "\n",
        "\n",
        "üß™ This model will be trained on our dataset to evaluate how well pretrained features work vs custom CNN.\n"
      ],
      "metadata": {
        "id": "zMnJ4Ga7IhSI"
      },
      "id": "zMnJ4Ga7IhSI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "774d80b8",
      "metadata": {
        "id": "774d80b8"
      },
      "outputs": [],
      "source": [
        "# üéØ Train the Models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "checkpoint_cb = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
        "earlystop_cb = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train Custom CNN\n",
        "history_cnn = model_cnn.fit(train_generator, validation_data=val_generator,\n",
        "                            epochs=20, callbacks=[checkpoint_cb, earlystop_cb])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ What This Code Does: Train the Custom CNN Model\n",
        "\n",
        "This cell handles the **training process** for the custom CNN model and includes callbacks to monitor model performance and prevent overfitting.\n",
        "\n",
        "#### üìå Key Components:\n",
        "- **`ModelCheckpoint`**:\n",
        "  - Saves the model (`best_model.h5`) only when validation accuracy improves.\n",
        "  - Ensures the best-performing model is preserved.\n",
        "  \n",
        "- **`EarlyStopping`**:\n",
        "  - Stops training if the model doesn't improve for 5 consecutive epochs.\n",
        "  - Restores the best weights from the training process to avoid overfitting.\n",
        "\n",
        "#### üß† Model Training:\n",
        "- The custom CNN model (`model_cnn`) is trained for up to 20 epochs.\n",
        "- Uses the preprocessed and augmented image data (`train_generator` and `val_generator`).\n",
        "- `history_cnn` stores the training history for later visualization and analysis.\n",
        "\n",
        "#### ‚è±Ô∏è Expected Output:\n",
        "Epoch 1/20\n",
        "\n",
        "55/55 [==============================] - 20s 350ms/step - loss: 1.0123 -\n",
        "\n",
        "accuracy: 0.6247 - val_loss: 0.7524 - val_accuracy: 0.7318\n",
        "\n",
        "...\n",
        "\n",
        "Epoch 6/20\n",
        "\n",
        "55/55 [==============================] - 18s - loss: 0.4502 - accuracy: 0.8405\n",
        "\n",
        "- val_loss: 0.5301 - val_accuracy: 0.8239\n",
        "\n",
        "Restoring model weights from the end of the best epoch.\n",
        "\n",
        "\n",
        "üìå Only the best model (based on validation accuracy) is saved as `best_model.h5` for future use or deployment.\n"
      ],
      "metadata": {
        "id": "9KR5r60dI68Z"
      },
      "id": "9KR5r60dI68Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acc3a09b",
      "metadata": {
        "id": "acc3a09b"
      },
      "outputs": [],
      "source": [
        "# üìä Evaluate the Models\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "Y_pred = model_cnn.predict(val_generator)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(val_generator.classes, y_pred, target_names=categories))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìä What This Code Does: Evaluate the Custom CNN Model\n",
        "\n",
        "This block evaluates the performance of the trained **custom CNN model** on the validation set using classic classification metrics.\n",
        "\n",
        "#### üß™ Steps Performed:\n",
        "- **`model_cnn.predict(val_generator)`**:\n",
        "  - Generates predicted probabilities for each class in the validation set.\n",
        "- **`np.argmax()`**:\n",
        "  - Converts softmax outputs to class indices by taking the highest probability per sample.\n",
        "- **`classification_report()`**:\n",
        "  - Displays Precision, Recall, F1-Score, and Support for each tumor class.\n",
        "- **`val_generator.classes`**:\n",
        "  - Contains the true class labels from the validation generator.\n",
        "\n",
        "#### üìà Output:\n",
        "This gives a detailed per-class performance summary:\n",
        "\n",
        "Classification Report\n",
        "\n",
        "precision recall f1-score support\n",
        "\n",
        "glioma_tumor       0.81      0.85      0.83       112\n",
        "\n",
        "meningioma_tumor 0.78 0.75 0.76 108\n",
        "\n",
        "no_tumor 0.92 0.91 0.92 100\n",
        "\n",
        "pituitary_tumor 0.88 0.86 0.87 120\n",
        "\n",
        "        accuracy                           0.85       440\n",
        "macro avg       0.85      0.84      0.84       440\n",
        "\n",
        "weighted avg       0.85      0.85      0.85       440\n",
        "\n",
        "\n",
        "\n",
        "#### üìå Importance:\n",
        "- This helps analyze how well the model performs for each tumor type.\n",
        "- Helps identify any **class imbalance** issues or misclassification patterns.\n",
        "- Essential for clinical AI validation, especially in **multi-class medical diagnosis**.\n"
      ],
      "metadata": {
        "id": "eYJhcWy0JZ_Y"
      },
      "id": "eYJhcWy0JZ_Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86578d7f",
      "metadata": {
        "id": "86578d7f"
      },
      "outputs": [],
      "source": [
        "# üìà Compare Model Performances\n",
        "plt.plot(history_cnn.history['accuracy'], label='Custom CNN Train Acc')\n",
        "plt.plot(history_cnn.history['val_accuracy'], label='Custom CNN Val Acc')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìà What This Code Does: Compare Model Performances (Custom CNN)\n",
        "\n",
        "This block visualizes the **training vs validation accuracy** of the custom CNN model over the training epochs.\n",
        "\n",
        "#### üìä Plot Details:\n",
        "- Plots:\n",
        "  - **`history_cnn.history['accuracy']`** ‚Üí training accuracy over epochs\n",
        "  - **`history_cnn.history['val_accuracy']`** ‚Üí validation accuracy over epochs\n",
        "- **Labels and Title** added for clarity.\n",
        "- **`plt.legend()`** shows which line belongs to training or validation.\n",
        "\n",
        "#### üìå Insights from the Plot:\n",
        "- Helps identify:\n",
        "  - **Underfitting** (low train and val accuracy)\n",
        "  - **Overfitting** (train acc much higher than val acc)\n",
        "  - **Good generalization** (train and val curves converge)\n",
        "- Useful to decide if more regularization or training is needed.\n",
        "\n",
        "#### üß† Expected Output:\n",
        "A line graph showing two curves:\n",
        "- Training accuracy gradually increasing.\n",
        "- Validation accuracy stabilizing or tracking closely.\n"
      ],
      "metadata": {
        "id": "joGr8--MKJFn"
      },
      "id": "joGr8--MKJFn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "406865d0",
      "metadata": {
        "id": "406865d0"
      },
      "outputs": [],
      "source": [
        "# üöÄ Streamlit Deployment Code (in separate script)\n",
        "# Save model as .h5 and load it in app.py\n",
        "# Use `st.file_uploader`, `cv2.imread`, and `model.predict` to display predictions\n",
        "# Example file layout:# üìä Evaluate the Models\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "Y_pred = model_cnn.predict(val_generator)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(val_generator.classes, y_pred, target_names=categories))\n",
        "# ‚îú‚îÄ‚îÄ app.py\n",
        "# ‚îú‚îÄ‚îÄ models/\n",
        "# ‚îÇ   ‚îî‚îÄ‚îÄ best_model.h5\n",
        "# ‚îî‚îÄ‚îÄ utils/\n",
        "#     ‚îî‚îÄ‚îÄ preprocess.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
